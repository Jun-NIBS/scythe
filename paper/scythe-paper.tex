\documentclass{bioinfo}
\copyrightyear{2012}
\pubyear{2012}

\begin{document}
\firstpage{1}

\title[Scythe]{Scythe: A tool for removing 3'-end adapter contaminants using Bayesian classification}
\author[Buffalo \textit{et~al}]{Vince Buffalo\,$^{1,}\footnote{to whom correspondence should be addressed}$, Joseph Fass\,$^{1}$ and Dawei Lin\,$^1$}
\address{$^{1}$Bioinformatics Core, UC Davis Genome Center}

\history{Received on XXXXX; revised on XXXXX; accepted on XXXXX}

\editor{Associate Editor: XXXXXXX}

\maketitle

\begin{abstract}

\section{Motivation:}
Modern sequencing technologies can leave artifactual contaminant
sequences at the 3'-end of reads. 3'-end regions also have the lowest
quality bases that are likely to be called incorrectly, which makes
identifying and removing 3'-end contaminants difficult. Fixed-number
mismatch approaches to remove contaminants perform poorly in these low
quality regions. Failing to remove such contaminants can seriously
confound downstream analyses like assembly and mapping.

\section{Results:} 
Scythe is a program designed specifically to remove 3'-end
contaminants. It searches for 3'-end contaminants and uses a Bayesian
model that considers individual base qualities to decide whether a
given match is a contaminant or background sequence. Even for a
variety of prior contamination rates, Scythe outperforms other adapter
removal software tools.

\section{Availability:}
Scythe is freely available under the MIT license at
\href{http://github.com/vsbuffalo/scythe}{http://github.com/vsbuffalo/scythe}.

\section{Contact:} \href{vsbuffalo@gmail.com}{vsbuffalo@gmail.com}
\end{abstract}

\section{Introduction}
Scythe focuses on 3'-end contaminants, specifically those due to
adapters or barcodes. It embraces the Unix Philosophy of ``programs
that do one thing well''
(\href{http://www.faqs.org/docs/artu/ch01s06.html}{http://www.faqs.org/docs/artu/ch01s06.html}). Many
second-generation sequencing technologies such as Illumina's Genome
Analyzer II and HiSeq have lower-quality 3'-end bases. These
low-quality bases are more likely to have nucleotides called
incorrectly, making contaminant identification more
difficult. Futhermore, 3'-end quality deterioration is not uniform
across all reads (see figure 1 in Supplementary Materials), there is
variation in the quality per base.

A common step in read quality improvement procedures is to remove
these low-quality 3'-end sequences from reads. This is thought to
increase mapping rates and improve assembly quality. However doing
quality-based 3'-end trimming before contaminant removal would remove
sequence that could be used (despite being unreliable) to identify the
contaminants more positively. Scythe takes the approach that it is
better to use full information, even if it's unreliable. How
unreliable a base is is indicated by the FASTQ quality score, which
can be incorporated into classification procedures.

Fixed-number of mismatch approaches have the disadvantage that they
don't differentially weight a mismatch on a low-quality base from a
mismatch on a high-quality base. Futhermore, the fixed-number could
easily be exhausted in a run of bad bases (which are quite common in
the 3'-end), even though every good-quality base perfectly matches the
contaminant sequence.


\begin{methods}
\section{String Matching in Scythe}

For each adapter in the file, Scythe looks for the best match in
terms of scores. A nucleotide match is scored as a 1, and a mismatch
is scored as a -1. Because Scythe doesn't address contaminants with
insertions or deletions, it doesn't use a standard alignment strategy
(i.e. dynamic programming). Instead, it considers every possible
substring of contamination: for a contaminant of length $l_c$, it
scores all possible substrings from the 5'-end of the contaminant. The
top scoring match is then used in the classification procedure. For
efficiency, other matches are not used in the classification
procedure.

The time complexity of Scythe's match algorithm for a single adapter
of length $l_a$ is $O(l_a^2 R)$ for a FASTQ file with $R$ entries.


\section{Bayesian Classification of Top-Scoring Matches}

There are two mutually exclusive and exhaustive events: a top scoring
match is a contaminant or it is random sequence (that happens to be
similar to the adapter contaminant). A likelihood for each of these
events, given probabilities of each base being called correctly and
which bases mismatch the contaminant sequence, can be calculated.

These likelihood functions assume models of error for each event. If
the top-scoring match is contaminant sequence (event $C$), the
likelihood $P(S | C)$ (where $S$ is the sequence match data) is:

$$ P(S | C) = \prod_i^{l_t} q_i^{m_i} \cdot (1-q_i)^{1 - m_i} $$

Where $m_i \in \{0, 1\}$ indicating whether the $i$ base is a
mismatch or match (respectively) and $q_i$ is the probability the $i$
base is called correctly (from the ASCII-encoded quality). $l_t$ is
the length of the top-scoring match.

If the top-scoring sequence is not a contaminant sequence (event
$C'$), it is assumed that the matches are just by chance. Thus, the
likelihood function is:

$$ P(S | C') = \prod_i^{l_t} \left(\frac{1}{4}\right)^{m_i} \cdot \left(\frac{3}{4}\right)^{1 - m_i} $$

These likelihoods can then be combined using Bayes' Thereom to give
the probability of contamination given then top-scoring match:

$$ P(C|S) = \frac{P(C) P(S|C)}{P(S)} $$

Where the denominator can be replaced with $P(S) = P(S | C)P(C) +
P(S | C') P(C')$ by the Law of Total Probability. $P(C'|S)$ is
calculated similarly. Since these are mutually exclusive and
exhaustive events, the /maximum a posteriori/ rule can be used to
classify a top-scoring sequence as either contaminated or
non-contaminated (e.g. if $P(C'|S) > P(C|S)$, the sequence is not
contaminated and visa-versa).

Required in this Bayesian formulation is the prior of contamination,
$P(C)$. Specifying the prior may seem like a nuisance, but it allows
ultimately allows for more accurate classification in a variety of
different contamination scenarios. The prior doesn't need to be
estimated increadibly well; one technique that works well is to view
the FASTQ file in the Unix command line tool less and search for the
5'-end bases of the adapter contaminant. The number of results on a
page of less output divided by the number of FASTQ entries on that
page works well as an initial guess for the prior.


\section{Results}
Scythe was tested against two similar program: Btrim
\cite{pmid21651976} and Cutadapt \cite{pmid19737799}. Both Btrim and
Cutadapt have the advantage over Scythe in that they can handle
insertions/deletions. Both also include quality trimmers, which
intentionally does not. 

To test Scythe, Btrim, and Cutadapt at 3' adapter contaminant removal,
random reads were generated and contaminated at fixed contamination
rates of 40\% and 70\%. FASTQ qualities from a Illumina Genome
Analyzer II run were added to these read sequences. Real base
qualities were used because properly modeling and simulating 3'-end
quality degradation is an arduous task. For the two fixed
contamination rates, ten replicate FASTQ files were generated randomly
to ensure contaminated and non-contaminated reads were well dispersed
across different read qualities. Each simulated FASTQ reads file
contains 10,000 entries.

Each program was run with varying parameters to see how true positive
and false positive rates change. Btrim uses a fixed number of
mismatches, so integer values from 0 to 10 were used. Cutadapt uses an
error rate for a matched sequence, which was varied from 0 to 0.95 in
0.05 increments. Likewise, Scythe also uses the same values for its
prior parameter. Each piece of software was run with all other options
off to ensure a fair comparison of 3'-end contaminant removal.

While Cutadapt and Scythe only trim files, Btrim occasionally removes
an read entirely from the sample. For comparison purposes, we count
this as trimming the entire length of a read. We compared the length
of the original simulated read to the trimmed read for all programs,
parameters, replicates, and contamination rates. This, combined with
information about whether a read was contaminated or not allows the
calculation of true positive and false positive rates. Also, we
investigate how many times Btrim, Cutadapt, and Scythe incorrectly
trim a read, e.g. whether the trimmed length is not equal to the
contaminate length for reads that were contaminated.

In these tests, we find that Scythe outperforms Btrim and Cutadapt in
terms of true positive rates for a variety of false positive rates
(see figure) across a variety of parameters. Furthermore, Scythe also
has fewer incorrectly trimmed reads across a variety of parameters
compared to Btrim and Cutadapt. We suspect this superior performance
is due to Scythe's (1) consideration of base-level qualities and (2)
Scythe's use of Bayesian model rather than a simple fixed-number of
mismatches or fixed-error approach.

\end{methods}

\section{Conclusion}

\section*{Acknowledgement}

\paragraph{Funding\textcolon} None.


\bibliographystyle{natbib}
% \bibliographystyle{achemnat}
% \bibliographystyle{plainnat}
% \bibliographystyle{abbrv}
% \bibliographystyle{bioinformatics}

\bibliography{references}


\end{document}
